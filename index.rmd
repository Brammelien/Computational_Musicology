---
title: "Dashes to my board"
author: "B. Slangen"
date: "2/15/2021"
output:
    flexdashboard::flex_dashboard:
    theme: flatly
---

```{r setup, include=FALSE}

library(forcats)
library(flexdashboard)
library(readr)
library(lubridate)
library(ggplot2)
library(tidyverse)
library(knitr)
library(DT)
library(spotifyr)
library(compmus)
library(plotly)
knitr::opts_chunk$set(echo=FALSE)
library(grid)
library(gridExtra)
library(tidymodels)
library(ggdendro)
library(heatmaply)

```

```{r}

Magnus_Corpus <- get_playlist_audio_features("", "61rge4nRNpMipwrZ1SojP7")
#Knocking <-
#Kids <-
#FoughttheLaw <-
#Walkthisway <-
#Higherground <-
#Shotthesherif<-

#Bobby
Boibby_Orginal <-
  get_tidy_audio_analysis("6HSXNV0b4M4cLJ7ljgVVeh") 

# eric 
Ericslive <-
  get_tidy_audio_analysis("5uhvUuQciVrP0p48NqSHaq") 

# Theguns
Theguns <-
  get_tidy_audio_analysis("4JiEyzf0Md7KEFFGWDDdCr")

Magnus_Corpus

```

```{r}
get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}  

```


```{r}
pop <- 
  get_playlist_audio_features("spotify", "37i9dQZF1DWWEcRhUVtL8n")
party <- get_playlist_audio_features("spotify", "37i9dQZF1DWTujiC7wfofZ")
workout <- get_playlist_audio_features("spotify", "37i9dQZF1DXaRL7xbcDl7X")
indie <-
  bind_rows(
    pop %>% mutate(playlist = "Indie Pop") %>% slice_head(n = 20),
    party %>% mutate(playlist = "Indie Party") %>% slice_head(n = 20),
    workout %>% mutate(playlist = "Indie Workout") %>% slice_head(n = 20)
  ) 

```

```{r}

Magnus_Corpus_features <-
  Magnus_Corpus %>%  # For your portfolio, change this to the name of your corpus.
  add_audio_analysis() %>% 
  mutate(
    track.name = factor(track.name),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))

```

```{r}
magnus_corpus_recipe <-
  recipe(track.name ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = Magnus_Corpus_features,          # Use the same name as the previous block.
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.
  # step_range(all_predictors())    # Sets range to [0, 1].


```

```{r}
magnus_corpus_cv <- Magnus_Corpus_features %>% vfold_cv(5)


```

```{r}
knn_model <-
  nearest_neighbor(neighbors = 1) %>%
  set_mode("classification") %>% 
  set_engine("kknn")
magnus_corpus_knn <- 
  workflow() %>% 
  add_recipe(magnus_corpus_recipe) %>% 
  add_model(knn_model) %>% 
  fit_resamples(
    magnus_corpus_cv, 
    control = control_resamples(save_pred = TRUE)
  )

```



```{r}
tree_model <-
  decision_tree() %>%
  set_mode("classification") %>% 
  set_engine("C5.0")
magnus_corpus_tree <- 
  workflow() %>% 
  add_recipe(magnus_corpus_recipe) %>% 
  add_model(tree_model) %>% 
  fit_resamples(
    magnus_corpus_cv, 
    control = control_resamples(save_pred = TRUE)
  )


```

```{r}
#magnus_corpus_tree %>% get_pr()
```

```{r}
workflow() %>% 
  add_recipe(magnus_corpus_recipe) %>% 
  add_model(tree_model) %>% 
  fit(Magnus_Corpus_features) %>% 
  pluck("fit", "fit", "fit") %>%
  summary()

```

```{r}
forest_model <-
  rand_forest() %>%
  set_mode("classification") %>% 
  set_engine("ranger", importance = "impurity")
magnus_corpus_forest <- 
  workflow() %>% 
  add_recipe(magnus_corpus_recipe) %>% 
  add_model(forest_model) %>% 
  fit_resamples(
    magnus_corpus_cv, 
    control = control_resamples(save_pred = TRUE)
  )

```

```{r}
#magnus_corpus_forest %>% get_pr()

```

```{r}
workflow() %>% 
  add_recipe(magnus_corpus_recipe) %>% 
  add_model(forest_model) %>% 
  fit(Magnus_Corpus_features) %>% 
  pluck("fit", "fit", "fit") %>%
  ranger::importance() %>% 
  enframe() %>% 
  mutate(name = fct_reorder(name, value)) %>% 
  ggplot(aes(name, value)) + 
  geom_col() + 
  coord_flip() +
  theme_minimal() +
  labs(x = NULL, y = "Importance")

```

```{r}
Magnus_Corpus_features %>%
  ggplot(aes(x = B, y = c02, colour = track.id, size = energy)) +
  geom_point(alpha = 0.8) +
  scale_color_viridis_d() +
  labs(
    x = "Timbre Component 1",
    y = "Timbre Component 2",
    size = "Energy",
    colour = "Playlist"
  )
```

Latest updates {.storyboard}
=====================================================================

### Classifier

```{r}
#magnus_corpus_knn %>% get_conf_mat()
magnus_corpus_knn %>% get_conf_mat() %>% autoplot(type = "mosaic")
magnus_corpus_knn %>% get_conf_mat() %>% autoplot(type = "heatmap")
```

***
As is not really visible since i was not able to make a mosaic or anything, my classification went horrible. I was not able to use tracknames, since they are all the same, which is not allowed. Factoring (for some reason) did not help as was shown for playlist = factor(playlist). I am now considering new option to organize my playlists in a way that classification can be used. Perhaps by assigning originals and covers, then seeing if it is capable of finding the right original with the right cover. However this would require a significant amount of new playlists, as otherwise it just uses each track.name as a separate class. Which is useless.


### Clustering

```{r}
halloween <-
  get_playlist_audio_features("", "61rge4nRNpMipwrZ1SojP7")%>%
  add_audio_analysis() %>%
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))


```

```{r}

halloween_juice <-
  recipe(
    track.id ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = halloween
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>% 
  # step_range(all_predictors()) %>% 
  prep(halloween %>% mutate(track.id = str_trunc(track.id, 20))) %>%
  juice() %>%
  column_to_rownames("track.id")
```

### Clustering 
```{r}
halloween_dist <- dist(halloween_juice, method = "manhattan")
```

```{r}
halloween_dist %>% 
  hclust(method = "complete") %>% # Try single, average, and complete.
  dendro_data() %>%
  ggdendrogram(rotate = TRUE)
  
```

```{r}
heatmaply(
  halloween_juice,
  hclustfun = hclust,
  hclust_method = "average",  # Change for single, average, or complete linkage.
  dist_method = "euclidean"
)


```

***
My clustering went better than my classification, however here the same issue occurs that it does not allow for the same names. I am going to see if it possible to use different factors for each playlist such that I can use the the trach kanmes instead of the id's. However this too would require a significant amount of new playlist. I did not have time yet to make these. 

Tempo {.storyboard}
=====================================================================

### Tempo analysis. 
```{r}
BobT <- Boibby_Orginal %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic() + 
  ggtitle("Bob Dylan")

EricT <- Ericslive %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic() + 
  ggtitle("Eric")

GunsT <- Theguns  %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()+ 
  ggtitle("Guns n roses")

```

```{r}
grid.arrange(BobT, EricT, GunsT, ncol=2)

```

***

Even though the Bob Dylan version and the Eric clapton version have a much slower feel that the Guns 'n Roses version, the tempograms do not seem to differ to much in BPM. I have tried verifying the tempo's through Google because of this reason. The tempo estimations for the Bob Dylan version and the Guns 'n roses version seem to vary rather much somewhere between 65 and 140 bpm, however for the Eric Clapton version they seem pretty consistent. Which I thought was interesting considering this shows two pretty strong tempo "powers". Something else I think is interesting to note is the tempo increase in the beginning and tempo decrease at the end in the Guns 'n Roses version, this change is clearly audible, which to me might be an indication that the estimations are rather accurate. Nonetheless these tempo estimations shown here are an interesting indication that the tempo more or less remained the same over the differnet cover versions. 


### Novelty 

```{r}
##Novelty
bobs <- Boibby_Orginal %>%
  select(segments) %>%
  unnest(segments) %>%
  mutate(loudness_max_time = start + loudness_max_time) %>%
  arrange(loudness_max_time) %>%
  mutate(delta_loudness = loudness_max - lag(loudness_max),song = "Bob Dylan") 

ericsn <- Ericslive  %>%
  select(segments) %>%
  unnest(segments) %>%
  mutate(loudness_max_time = start + loudness_max_time) %>%
  arrange(loudness_max_time) %>%
  mutate(delta_loudness = loudness_max - lag(loudness_max), song = "Eric Clapton") 

Gunsn <- Theguns %>%
  select(segments) %>%
  unnest(segments) %>%
  mutate(loudness_max_time = start + loudness_max_time) %>%
  arrange(loudness_max_time) %>%
  mutate(delta_loudness = loudness_max - lag(loudness_max), song = "Guns 'n Roses") 

feed_this <-
  bobs  %>%
  bind_rows(ericsn) %>%
  bind_rows(Gunsn)
feed_this %>%
  ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
  geom_line() +
  theme_minimal() +
  facet_wrap( ~song, scales = "free")+
  labs(x = "Time (s)", y = "Novelty")

```

***
Even though the grids vary (pay attention to different x and y scales), the degree of novelty does not seem to differ significantly between the versions. We see one outlier in the guns n roses graph that seems to marginalize the other values around 240. This is a little spike after a silent part, where they start singing "knock knock knocking" again. Other than that we see in general novelties with a maximum of 15. Especially in the Eric Clapton version. Which is expected since this is a rather consistent song.

### irrelevant

```{r}
bebop <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "55s8gstHcaCyfU47mQgLrB"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
bigband <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "2cjIvuw4VVOQSeUAZfNiqY"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
jazz <-
  bebop %>%
  mutate(genre = "Bebop") %>%
  bind_rows(bigband %>% mutate(genre = "Big Band"))

jazz %>%
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  ) %>%
  unnest(sections) %>%
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = genre,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Genre",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )
```




```{r} 

jazz <-
  bebop %>%
  mutate(genre = "Bebop") %>%
  bind_rows(bigband %>% mutate(genre = "Big Band"))
jazz %>%
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) %>%
  select(genre, timbre) %>%
  compmus_gather_timbre() %>%
  ggplot(aes(x = basis, y = value, fill = genre)) +
  geom_violin() +
  scale_fill_viridis_d() +
  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Genre")

```

*** 
Some text here

INTRO
====================================================================

### Plot tab
For my first representation I have tried to create an overview of the different versions of cover songs in my Corpus. Sadly I have had some trouble getting the artists names from Spotify which made me unable to give information about this. Even a more major issue I faced was the group_by function, which can only group songs that have the exact same title. Cover songs sadly do not always have exctly the same title. In the graph below you see an attempt to show a basic distribution of my Corpus based on the energy (x-axis) and valence (y-axis). I chose these two values to give an insight in the overal feel of a song according to spotify. With this I attempted to create a feeling of how far the feel of the cover songs was apart from the original (and possibly other covers of the same song), to give a stronger sense of the differences I attempted to draw lines between different versions of the same song. It is visble that I still struggle with correct imlementation, I seem to lose colors and visibility now I have corrected the issue with the song names.


### Wavferform tab
As you can see ive included my waveform comparisons between different versions of Knocking on heavens door. I've chosen this one, because it shows absolutely no similarity what so ever. For the Bob Dylan version this makes sense as it is significantly shorter than the other version. However, the Eric Clapton version and the Guns 'N Roses version are very similar in duration. I think this is a very interesting representation on how different the "same" songs can be. I will try to show this more with graphs in the future, as making waveform analysis for all songs is not feasible nor informative. I tried showing them in a rows overview, which is nicer, however because of the code that is shown this really messes up the overview. 






The messed up plot
=====================================================================
```{r}

Ordered_magnus_corpus <- Magnus_Corpus %>%
    # Arrange data frame
  group_by(track.name)
  # Reorder countries by working hours in 2006

plot <- ggplot(Ordered_magnus_corpus, aes(x = energy, y = valence, group = track.name)) +
geom_point() +
geom_path(arrow = arrow(length = unit(1.5, "mm"), type = "closed"))

ggplotly(plot)



          


```



Waveform analysis
=====================================================================

Bobby VS. Eric
-----------------------------------------------------------------------



```{r}
#Bobby
Boibby_Orginal <-
  get_tidy_audio_analysis("6HSXNV0b4M4cLJ7ljgVVeh") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
## Eric
Ericslive <-
  get_tidy_audio_analysis("5uhvUuQciVrP0p48NqSHaq") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

compmus_long_distance(
  Boibby_Orginal %>% mutate(pitches = map(pitches, compmus_normalise, "euclidean")),
  Ericslive %>% mutate(pitches = map(pitches, compmus_normalise, "euclidean")),
  feature = pitches,
  method = "euclidean"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "Bob Dylan (original)", y = "Eric Clapton (Live)") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)

```



Bobby VS. The Guns
-----------------------------------------------------------------------



```{r}
#Bobby
Boibby_Orginal <-
  get_tidy_audio_analysis("6HSXNV0b4M4cLJ7ljgVVeh") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
## Theguns
Theguns <-
  get_tidy_audio_analysis("4JiEyzf0Md7KEFFGWDDdCr") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

compmus_long_distance(
  Boibby_Orginal %>% mutate(pitches = map(pitches, compmus_normalise, "euclidean")),
  Theguns %>% mutate(pitches = map(pitches, compmus_normalise, "euclidean")),
  feature = pitches,
  method = "euclidean"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "Bob Dylan (original)", y = "Guns 'n Roses") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)

```


Eric VS. The Guns
-----------------------------------------------------------------------
```{r}
# Eric
Ericslive <-
  get_tidy_audio_analysis("5uhvUuQciVrP0p48NqSHaq") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
## Guns
Theguns <-
  get_tidy_audio_analysis("4JiEyzf0Md7KEFFGWDDdCr") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

compmus_long_distance(
  Ericslive %>% mutate(pitches = map(pitches, compmus_normalise, "euclidean")),
  Theguns %>% mutate(pitches = map(pitches, compmus_normalise, "euclidean")),
  feature = pitches,
  method = "euclidean"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "Eric Clapton (Live)", y = "Guns 'n Roses") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)

```






pitch and timbre {.storyboard}
=====================================================================


### Dylan

```{r dylan}
dylan <-
  get_tidy_audio_analysis('6HSXNV0b4M4cLJ7ljgVVeh') %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  dylan %>% 
    compmus_self_similarity(pitches, "aitchison") %>% 
    mutate(d = d / max(d), type = "Chroma"),
  dylan %>% 
    compmus_self_similarity(timbre, "euclidean") %>% 
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "")
```

***
Some lines here

### Clapton


```{r clapton}
clapton <-
  get_tidy_audio_analysis("5uhvUuQciVrP0p48NqSHaq") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  clapton %>% 
    compmus_self_similarity(pitches, "aitchison") %>% 
    mutate(d = d / max(d), type = "Chroma"),
  clapton %>% 
    compmus_self_similarity(timbre, "euclidean") %>% 
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "")

```

***
Some text here

### Roses

```{r gunsnroses}


gunsnroses<-
  get_tidy_audio_analysis("4JiEyzf0Md7KEFFGWDDdCr") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  gunsnroses %>% 
    compmus_self_similarity(pitches, "aitchison") %>% 
    mutate(d = d / max(d), type = "Chroma"),
  gunsnroses %>% 
    compmus_self_similarity(timbre, "euclidean") %>% 
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "")

```

***
Some lines here

### Timbre comparison


```{r timbre, echo=FALSE}
timbredylan <- dylan %>%
  compmus_gather_timbre() %>%
  mutate(song = "dylan")

timbreclapton <- clapton %>%
  compmus_gather_timbre() %>%
  mutate(song = "clapton")

gunsnrosestimbre <-gunsnroses %>%
  compmus_gather_timbre()%>%
  mutate(song = "gunsnroses")

bind_rows(timbredylan, timbreclapton, gunsnrosestimbre) %>%
  ggplot(
    aes(
     x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  )+
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +          
  facet_wrap((~song))
  theme_classic()
  


```

*** 
We can see a bigger magnitude for the guns n roses song in more pitches than for the other two songs. This is to be expected hwne listening to these songs. The guns n roses version has the most varriation in it, and actually sounds "biggest". The clapton verson is much more calm and steady. Where the Dylan version is actual pretty quite and steady. Which is since its much smaller length also to be expected.



Some chords {.storyboard}
=======================================================================

### Some chords
```{r}

circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(5, 3, 3.5, 2, 4.5, 4, 2, 4.5, 2.0, 3.5, 1.5, 4.0)
minor_key <-
  c(5.0, 2.0, 3.5, 4.5, 2.0, 4.0, 2.0, 4.5, 3.5, 2.0, 1.5, 4.0)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```



```{r}
Dylan_chords <-
  get_tidy_audio_analysis("6HSXNV0b4M4cLJ7ljgVVeh") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )  


Plot1 <- Dylan_chords %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  )  

Dylan <- Plot1 %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "Time (s)", y = "") +
  xlim(55, 85)

```

```{r}
Eric_chords <-
  get_tidy_audio_analysis("5uhvUuQciVrP0p48NqSHaq") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Plot2 <- Eric_chords %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  )  
Ericplot <- Plot2%>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "Time (s)", y = "") +
  xlim(65, 105)

```

```{r}
Guns_chords <-
  get_tidy_audio_analysis("4JiEyzf0Md7KEFFGWDDdCr") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  ) %>%
  mutate(song = "Guns")

plot3 <- Guns_chords %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) 

Gunsplot <- plot3 %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "Time (s)", y = "") +
  xlim(52, 90)

```

```{r}
combinedchords <-
  Plot1 %>%
  mutate(song = " Dylan") %>%
  bind_rows(Plot2 %>% mutate(song =  "Eric")) %>%
  bind_rows(plot3 %>% mutate(song =  "guns"))



```


```{r} 

combinedchords %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c() +
  theme_classic() +
  labs(x = "Time (s)", y = "") +
  facet_wrap(~song, scales = "free")

```


***

I am currently working on a different way to extract the most dominant/stronger occuring chords from a variaty of sorts. If I manage this I will include this here, otherwise some extra chords graphs will be added from a variety of songs from the corpus. 
